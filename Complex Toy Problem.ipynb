{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Showing off Sequential Neural Likelihood/Likelihoord Ratio method on the example problem from https://arxiv.org/abs/1805.07226 detailed in A.1 with posteriors plotted in Figure 5a. \n",
    "\n",
    "SNLR is performing quite well. Still need to figure out why SNL isn't working as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as np\n",
    "import numpy as onp\n",
    "import optax\n",
    "from trax.jaxboard import SummaryWriter\n",
    "from lbi.prior import SmoothedBoxPrior\n",
    "from lbi.dataset import getDataLoaderBuilder\n",
    "from lbi.diagnostics import MMD, ROC_AUC, LR_ROC_AUC\n",
    "from lbi.sequential.sequential import sequential\n",
    "from lbi.models.base import get_train_step, get_valid_step\n",
    "from lbi.models.flows import InitializeFlow\n",
    "from lbi.models.classifier import InitializeClassifier\n",
    "from lbi.trainer import getTrainer\n",
    "from lbi.sampler import hmc\n",
    "from lbi.examples.TractableProblem.tractable_problem_functions import get_simulator\n",
    "\n",
    "import corner\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove top and right axis from plots\n",
    "mpl.rcParams['axes.spines.right'] = False\n",
    "mpl.rcParams['axes.spines.top'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = \"classifier\"  # \"classifier\" or \"flow\"\n",
    "\n",
    "seed = 1234\n",
    "rng, model_rng, hmc_rng = jax.random.split(jax.random.PRNGKey(seed), num=3)\n",
    "\n",
    "# Model hyperparameters\n",
    "num_layers = 5\n",
    "hidden_dim = 512\n",
    "\n",
    "# Optimizer hyperparmeters\n",
    "max_norm = 1e-3\n",
    "learning_rate = 3e-4\n",
    "weight_decay = 1e-1\n",
    "sync_period = 5\n",
    "slow_step_size = 0.5\n",
    "\n",
    "# Train hyperparameters\n",
    "nsteps = 250000\n",
    "patience = 500\n",
    "eval_interval = 100\n",
    "\n",
    "# Sequential hyperparameters\n",
    "num_rounds = 1\n",
    "num_initial_samples = 100000\n",
    "num_samples_per_round = 1000\n",
    "num_chains = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up simulation and observables\n",
    "simulate, obs_dim, theta_dim = get_simulator()\n",
    "\n",
    "# set up true model for posterior inference test\n",
    "true_theta = np.array([0.7, -2.9, -1.0, -0.9, 0.6])\n",
    "X_true = simulate(rng, true_theta, num_samples_per_theta=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader_builder = getDataLoaderBuilder(\n",
    "    sequential_mode=model_type,\n",
    "    batch_size=128,\n",
    "    train_split=0.95,\n",
    "    num_workers=0,\n",
    "    add_noise=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up prior\n",
    "log_prior, sample_prior = SmoothedBoxPrior(\n",
    "    theta_dim=theta_dim, lower=-3.0, upper=3.0, sigma=0.02\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model\n",
    "if model_type == \"classifier\":\n",
    "    model_params, loss, log_pdf = InitializeClassifier(\n",
    "        model_rng=model_rng,\n",
    "        obs_dim=obs_dim,\n",
    "        theta_dim=theta_dim,\n",
    "        num_layers=num_layers,\n",
    "        hidden_dim=hidden_dim,\n",
    "    )\n",
    "else:\n",
    "    model_params, loss, (log_pdf, sample) = InitializeFlow(\n",
    "        model_rng=model_rng,\n",
    "        obs_dim=obs_dim,\n",
    "        theta_dim=theta_dim,\n",
    "        num_layers=num_layers,\n",
    "        hidden_dim=hidden_dim,\n",
    "    )\n",
    "\n",
    "# Create optimizer\n",
    "optimizer = optax.chain(\n",
    "    # Set the parameters of Adam optimizer\n",
    "    optax.adamw(\n",
    "        learning_rate=learning_rate,\n",
    "        weight_decay=weight_decay,\n",
    "        b1=0.9,\n",
    "        b2=0.999,\n",
    "        eps=1e-8,\n",
    "    ),\n",
    "    optax.adaptive_grad_clip(max_norm),\n",
    ")\n",
    "optimizer = optax.lookahead(\n",
    "    optimizer, sync_period=sync_period, slow_step_size=slow_step_size\n",
    ")\n",
    "\n",
    "model_params = optax.LookaheadParams.init_synced(model_params)\n",
    "opt_state = optimizer.init(model_params)\n",
    "\n",
    "# Create trainer\n",
    "train_step = get_train_step(loss, optimizer)\n",
    "valid_step = get_valid_step({\"valid_loss\": loss})\n",
    "\n",
    "trainer = getTrainer(\n",
    "    train_step,\n",
    "    valid_step=valid_step,\n",
    "    nsteps=nsteps,\n",
    "    eval_interval=eval_interval,\n",
    "    patience=patience,\n",
    "    logger=None,\n",
    "    train_kwargs=None,\n",
    "    valid_kwargs=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARTING ROUND 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Valid loss: 0.0025:   2%|▏         | 4490/250000 [04:12<3:49:50, 17.80it/s]\n",
      "/Users/jtam/opt/miniconda3/envs/lbi/lib/python3.9/site-packages/numpyro/infer/mcmc.py:269: UserWarning: There are not enough devices to run parallel chains: expected 2 but got 1. Chains will be drawn sequentially. If you are running MCMC in CPU, consider using `numpyro.set_host_device_count(2)` at the beginning of your program. You can double-check how many devices are available in your system using `jax.local_device_count()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyboard interrupted. Stopping early\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [00:20<00:00, 95.56it/s, 7 steps of size 6.23e-01. acc. prob=0.83] \n",
      "sample: 100%|██████████| 2000/2000 [00:18<00:00, 109.52it/s, 7 steps of size 5.28e-01. acc. prob=0.89]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                mean       std    median      5.0%     95.0%     n_eff     r_hat\n",
      "Param:0[0]      0.68      0.02      0.68      0.65      0.70   1633.97      1.00\n",
      "Param:0[1]     -2.87      0.02     -2.87     -2.90     -2.84   2303.68      1.00\n",
      "Param:0[2]      0.47      0.45      0.49     -0.23      1.16   1059.04      1.00\n",
      "Param:0[3]      0.29      0.32      0.30     -0.21      0.81   2324.96      1.00\n",
      "Param:0[4]      1.67      0.56      1.68      0.81      2.63   1475.34      1.00\n",
      "\n",
      "Number of divergences: 85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jtam/Projects/LBI/lbi/sequential/sequential.py:243: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "# Train model sequentially\n",
    "model_params, Theta_post = sequential(\n",
    "    rng,\n",
    "    X_true,\n",
    "    model_params,\n",
    "    log_pdf,\n",
    "    log_prior,\n",
    "    sample_prior,\n",
    "    simulate,\n",
    "    opt_state,\n",
    "    trainer,\n",
    "    data_loader_builder,\n",
    "    num_rounds=num_rounds,\n",
    "    num_initial_samples=num_initial_samples,\n",
    "    num_samples_per_round=num_samples_per_round,\n",
    "    num_samples_per_theta=1,\n",
    "    num_chains=num_chains,\n",
    "    logger=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def potential_fn(theta):\n",
    "    if len(theta.shape) == 1:\n",
    "        theta = theta[None, :]\n",
    "    log_post = (\n",
    "        -log_pdf(\n",
    "            model_params.fast if hasattr(model_params, \"fast\") else model_params,\n",
    "            X_true,\n",
    "            theta,\n",
    "        )\n",
    "        - log_prior(theta)\n",
    "    )\n",
    "    return log_post.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jtam/opt/miniconda3/envs/lbi/lib/python3.9/site-packages/numpyro/infer/mcmc.py:269: UserWarning: There are not enough devices to run parallel chains: expected 2 but got 1. Chains will be drawn sequentially. If you are running MCMC in CPU, consider using `numpyro.set_host_device_count(2)` at the beginning of your program. You can double-check how many devices are available in your system using `jax.local_device_count()`.\n",
      "  warnings.warn(\n",
      "sample: 100%|██████████| 4000/4000 [00:34<00:00, 114.98it/s, 3 steps of size 5.44e-01. acc. prob=0.88]\n",
      "sample: 100%|██████████| 4000/4000 [00:29<00:00, 133.83it/s, 3 steps of size 6.08e-01. acc. prob=0.85]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                mean       std    median      5.0%     95.0%     n_eff     r_hat\n",
      "Param:0[0]      0.68      0.02      0.68      0.66      0.71   4041.89      1.00\n",
      "Param:0[1]     -2.90      0.02     -2.90     -2.93     -2.87   3791.87      1.00\n",
      "Param:0[2]      0.52      0.40      0.52     -0.16      1.18   4680.21      1.00\n",
      "Param:0[3]      0.26      0.33      0.27     -0.28      0.79   4019.45      1.00\n",
      "Param:0[4]      1.67      0.57      1.68      0.70      2.62   3292.51      1.00\n",
      "\n",
      "Number of divergences: 143\n"
     ]
    }
   ],
   "source": [
    "num_chains = 2\n",
    "init_theta = sample_prior(rng, num_samples=num_chains)\n",
    "\n",
    "mcmc = hmc(\n",
    "    rng,\n",
    "    potential_fn,\n",
    "    init_theta,\n",
    "    adapt_step_size=True,\n",
    "    adapt_mass_matrix=True,\n",
    "    dense_mass=True,\n",
    "    step_size=1e0,\n",
    "    max_tree_depth=6,\n",
    "    num_warmup=2000,\n",
    "    num_samples=2000,\n",
    "    num_chains=num_chains,\n",
    ")\n",
    "mcmc.print_summary()\n",
    "\n",
    "theta_samples = mcmc.get_samples(group_by_chain=False).squeeze()\n",
    "\n",
    "theta_dim = theta_samples.shape[-1]\n",
    "true_theta = onp.array([0.7, -2.9, -1.0, -0.9, 0.6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "corner.corner(\n",
    "    onp.array(theta_samples),\n",
    "    range=[(-3, 3) for i in range(theta_dim)],\n",
    "    truths=true_theta,\n",
    "    bins=75,\n",
    "    smooth=(1.0),\n",
    "    smooth1d=(1.0),\n",
    ")\n",
    "plt.show()\n",
    "# plt.savefig(\"hmc_corner.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ed7feb0e0c2c0e31fc56374bef8fd2861d1bb01dc88a9139cf9a49b95fee9c74"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit ('lbi': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
